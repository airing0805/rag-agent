{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93181bb2-841b-4aee-a1d1-8fb270e5cb24",
   "metadata": {},
   "source": [
    "# Model IO模块课程演练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc23aec0-5f08-40ec-b988-6b4e19661a1f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in d:\\soft\\python\\lib\\site-packages (0.0.306)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\soft\\python\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\soft\\python\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\soft\\python\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in d:\\soft\\python\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\soft\\python\\lib\\site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\soft\\python\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in d:\\soft\\python\\lib\\site-packages (from langchain) (0.0.41)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in d:\\soft\\python\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in d:\\soft\\python\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in d:\\soft\\python\\lib\\site-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\soft\\python\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\soft\\python\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\soft\\python\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\soft\\python\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\soft\\python\\lib\\site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\soft\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\soft\\python\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\soft\\python\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in d:\\soft\\python\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\soft\\python\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\soft\\python\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\soft\\python\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in d:\\soft\\python\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\soft\\python\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "## 导入依赖库\n",
    "\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb802de5-723b-42d5-8c22-61f9e035f1b2",
   "metadata": {},
   "source": [
    "## 1. 什么是LCEL?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f9779-dcb5-483f-a70f-989de8a58646",
   "metadata": {},
   "source": [
    "LangChain于8月1日0.254版本更新，声称采用新的语法来创建带和组合功能的Chain，同时提供一个新的接口，支持批处理、异步和流处理，将这种语法成\n",
    "为LangChain Expression Language(LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96435af-97f9-4508-9064-90a7264ad066",
   "metadata": {},
   "source": [
    "## 2. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99415e02-03a3-4820-aa33-a65599cd4b50",
   "metadata": {},
   "source": [
    "### 2.1 Model的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2d692-f294-41fa-be0f-9bf3a9773827",
   "metadata": {},
   "source": [
    "LLMs: LangChain 的核心组件。LangChain并不提供自己的LLMs，而是为与许多不同的LLMs（OpenAI、Cohere、Hugging Face等）进行交互提供了一个标准\n",
    "接口。（类似于Completion）\n",
    "\n",
    "Chat Models: 语言模型的一种变体。虽然聊天模型在内部使用了语言模型，但它们提供的接口略有不同。与其暴露一个“输入文本，输出文本”的API不同，\n",
    "它们提供了一个以“聊天消息”作为输入和输出的接口。(类似于Chat Completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a792d17e-4ff0-486b-b298-274f63ca7092",
   "metadata": {},
   "source": [
    "### 2.2 LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5237b132-3665-49fc-96b9-fa4af20ebb50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\python\\Lib\\site-packages\\langchain\\llms\\openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "D:\\soft\\python\\Lib\\site-packages\\langchain\\llms\\openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'机器学习是一种人工智能（AI）的分支领域，旨在让机器通过从数据中学习来改善性能，而不是显式地编程。机器学习涉及开发算法和模型，使机器能够通过数据获取知识和经验，并根据这些知识和经验来做出预测或做出决策。机器学习方法基于统计学、优化算法和计算机科学的原理。它可以应用于各个领域，例如图像和语音识别、自然语言处理、推荐系统、金融预测等。机器学习可以分为监督学习、无监督学习和强化学习等不同类型。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\",openai_api_base = \"https://newone.nxykj.tech/v1\")\n",
    "\n",
    "llm.invoke(\"什么是机器学习？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071f3ee8-31eb-4bb5-a250-867e6eb0a34a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大模型是指指数级别或更大的模型，通常需要大量的计算资源和存储空间来训练和部署。大模型通常包含数千万或数亿个参数，能够处理复杂的任务和数据，如自然语言处理，语音识别，计算机视觉等领域。大模型的典型例子包括深度学习模型，如BERT、GPT-3等。大模型的训练和使用需要高性能计算技术和高效的算法设计，是人工智能和机器学习领域的热门研究方向之一。'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"什么是大模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3211c-3f7e-4de5-99c4-1253dcc33b2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "OpenAI API 地址：https://api.python.langchain.com/en/latest/llms/langchain.llms.openai.OpenAI.html#langchain.llms.openai.OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc9ad88-f07c-41b3-a6c5-61e6896acd9d",
   "metadata": {},
   "source": [
    "### 2.3 Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c3ffa8-4dbf-464a-872c-38322c67ce3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_base = \"https://newone.nxykj.tech/v1\")\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "messages = [SystemMessage(content=\"你是一个智能助手\"),\n",
    " HumanMessage(content=\"第二十一届世界杯在哪儿举行的?\"),\n",
    " AIMessage(content=\"在俄罗斯\"), \n",
    " HumanMessage(content=\"冠军是哪个球队\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d91b4c1-a1e2-4b4c-b8ac-f3ae7f158105",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='法国队是第二十一届世界杯的冠军。')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1c7933-2cd9-4e44-aacc-8517590dc9d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'法国获得了第二十一届世界杯的冠军。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b197de-b369-4d49-988b-045948691f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2018年世界杯的冠军是法国队。')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b5c58-c710-4979-a4d4-dcdc6580b143",
   "metadata": {},
   "source": [
    "ChatOpenAI API地址：https://api.python.langchain.com/en/latest/chat_models/langchain.chat_models.openai.ChatOpenAI.html#langchain.chat_models.openai.ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a917a6-4cb5-40aa-8718-43b2372b219d",
   "metadata": {},
   "source": [
    "## 3.prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8cdb4-316b-4254-8514-67d94243b401",
   "metadata": {},
   "source": [
    "一个语言模型的提示是用户提供的一组指令或输入，用于引导模型的响应，帮助它理解上下文并生成相关和连贯的基于语言的输出，例如回答问题、完成句子或\n",
    "进行对话。\n",
    "\n",
    "提示模板（Prompt Templates）：参数化的模型输入\n",
    "\n",
    "示例选择器（Example Selectors）：动态选择要包含在提示中的示例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ab6eb-4c9b-4892-a0f1-63b777b3512c",
   "metadata": {},
   "source": [
    "### 3.1 Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6abf87-8eb9-49bf-a4fa-611617d7424a",
   "metadata": {},
   "source": [
    "#### 1. use PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6715235e-373d-4261-bf1c-d1f7478bddf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 可以动态传入参数\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb7a72c-4051-4078-a67e-ffc212a074ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 也可以不传参数\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04da45e0-0000-4145-8789-4a1b3a34587d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the tomato turn red?\\n\\nBecause it saw the salad dressing!'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt_template.format())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aa929e-d943-435f-887b-245683c851b7",
   "metadata": {},
   "source": [
    "#### 2.use ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d14135f-88e2-4010-b66a-7aa164f3dfe0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='My name is Bob. How can I assist you today?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "\n",
    "chat_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd8814f-db57-449a-9a2d-5def88242b08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我了解，人们常常会经历烦恼和困扰。但是，积极的态度和心态可以帮助我们应对困难和压力。让我来分享一些帮助你变得更积极的建议：\\n\\n1. 寻找支持：与朋友、家人或专业人士交流，分享你的烦恼，听取他们的建议和支持。\\n\\n2. 培养感恩之心：每天花一些时间思考你所拥有的，珍惜和感激这些东西。感恩之心可以帮助你更加积极地看待生活。\\n\\n3. 设定目标：制定一些具体的、可量化的目标，并制定实现这些目标的计划。追求目标可以给你带来成就感和动力。\\n\\n4. 培养健康的生活习惯：保持良好的饮食、充足的睡眠和适度的运动可以提升你的身体和心理健康。\\n\\n5. 积极思考：尝试改变消极的思维习惯，转而寻找积极的解释和观点。积极思考可以帮助你更好地应对挑战和困难。\\n\\n6. 寻找乐趣和爱好：找到一些你真正喜欢的活动或爱好，并定期参与其中。这样可以让你感到充实和快乐。\\n\\n7. 培养自我关爱：给自己一些时间和空间，关注自己的需求和感受。学会放松和照顾自己，这样你将更有能力面对困难。\\n\\n请记住，积极的态度需要时间和努力来培养。每天都尝试一些小的积极行为，逐渐改变你的思维方式。相信自己，你一定能够变得更积极和乐观！')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain.schema.messages import SystemMessage\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"你是一个智能助手，让用户变得更积极\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_model(chat_template.format_messages(text=\"我最近比较烦\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c5370-8c8b-4c6e-b8c6-87873e80e774",
   "metadata": {},
   "source": [
    "#### 3.Few-shot prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5f24e1-25ed-4081-9397-84d1a471501a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "examples  = [\n",
    "{\n",
    "\"question\": \"穆罕默德·阿里（Muhammad Ali）和艾伦·图灵（Alan Turing）中哪个活得更长？\",\n",
    "\"answer\":\n",
    "\"\"\"\n",
    "这里需要后续问题吗：是。\n",
    "后续问题：穆罕默德·阿里去世时多少岁？\n",
    "中间答案：穆罕默德·阿里去世时74岁。\n",
    "后续问题：艾伦·图灵去世时多少岁？\n",
    "中间答案：艾伦·图灵去世时41岁。\n",
    "因此最终答案是：穆罕默德·阿里\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "\"question\": \"craigslist的创始人是何时出生的？\",\n",
    "\"answer\":\n",
    "\"\"\"\n",
    "这里需要后续问题吗：是。\n",
    "后续问题：craigslist的创始人是谁？\n",
    "中间答案：craigslist的创始人是Craig Newmark。\n",
    "后续问题：Craig Newmark是什么时候出生的？\n",
    "中间答案：Craig Newmark于1952年12月6日出生。\n",
    "因此最终答案是：1952年12月6日\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "\"question\": \"乔治·华盛顿（George Washington）的母亲的母亲父亲是谁？\",\n",
    "\"answer\":\n",
    "\"\"\"\n",
    "这里需要后续问题吗：是。\n",
    "后续问题：乔治·华盛顿的母亲是谁？\n",
    "中间答案：乔治·华盛顿的母亲是玛丽·鲍尔·华盛顿（Mary Ball Washington）。\n",
    "后续问题：玛丽·鲍尔·华盛顿的父亲是谁？\n",
    "中间答案：玛丽·鲍尔·华盛顿的父亲是约瑟夫·鲍尔（Joseph Ball）。\n",
    "因此最终答案是：约瑟夫·鲍尔\n",
    "\"\"\"\n",
    "},\n",
    "{\n",
    "\"question\": \"《大白鲨》和《皇家赌场》的导演都来自同一个国家吗？\",\n",
    "\"answer\":\n",
    "\"\"\"\n",
    "这里需要后续问题吗：是。\n",
    "后续问题：《大白鲨》的导演是谁？\n",
    "中间答案：《大白鲨》的导演是史蒂文·斯皮尔伯格（Steven Spielberg）。\n",
    "后续问题：史蒂文·斯皮尔伯格来自哪里？\n",
    "中间答案：美国。\n",
    "后续问题：《皇家赌场》的导演是谁？\n",
    "中间答案：《皇家赌场》的导演是马丁·坎贝尔（Martin Campbell）。\n",
    "后续问题：马丁·坎贝尔来自哪里？\n",
    "中间答案：新西兰。\n",
    "因此最终答案是：不是\n",
    "\"\"\"\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265fefb6-52be-439a-83aa-6d47dfdf41e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 穆罕默德·阿里（Muhammad Ali）和艾伦·图灵（Alan Turing）中哪个活得更长？\n",
      "\n",
      "这里需要后续问题吗：是。\n",
      "后续问题：穆罕默德·阿里去世时多少岁？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "后续问题：艾伦·图灵去世时多少岁？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "因此最终答案是：穆罕默德·阿里\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"], \n",
    "    template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f133de-004a-451d-9edd-96c37902059c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 穆罕默德·阿里（Muhammad Ali）和艾伦·图灵（Alan Turing）中哪个活得更长？\n",
      "\n",
      "这里需要后续问题吗：是。\n",
      "后续问题：穆罕默德·阿里去世时多少岁？\n",
      "中间答案：穆罕默德·阿里去世时74岁。\n",
      "后续问题：艾伦·图灵去世时多少岁？\n",
      "中间答案：艾伦·图灵去世时41岁。\n",
      "因此最终答案是：穆罕默德·阿里\n",
      "\n",
      "\n",
      "Question: craigslist的创始人是何时出生的？\n",
      "\n",
      "这里需要后续问题吗：是。\n",
      "后续问题：craigslist的创始人是谁？\n",
      "中间答案：craigslist的创始人是Craig Newmark。\n",
      "后续问题：Craig Newmark是什么时候出生的？\n",
      "中间答案：Craig Newmark于1952年12月6日出生。\n",
      "因此最终答案是：1952年12月6日\n",
      "\n",
      "\n",
      "Question: 乔治·华盛顿（George Washington）的母亲的母亲父亲是谁？\n",
      "\n",
      "这里需要后续问题吗：是。\n",
      "后续问题：乔治·华盛顿的母亲是谁？\n",
      "中间答案：乔治·华盛顿的母亲是玛丽·鲍尔·华盛顿（Mary Ball Washington）。\n",
      "后续问题：玛丽·鲍尔·华盛顿的父亲是谁？\n",
      "中间答案：玛丽·鲍尔·华盛顿的父亲是约瑟夫·鲍尔（Joseph Ball）。\n",
      "因此最终答案是：约瑟夫·鲍尔\n",
      "\n",
      "\n",
      "Question: 《大白鲨》和《皇家赌场》的导演都来自同一个国家吗？\n",
      "\n",
      "这里需要后续问题吗：是。\n",
      "后续问题：《大白鲨》的导演是谁？\n",
      "中间答案：《大白鲨》的导演是史蒂文·斯皮尔伯格（Steven Spielberg）。\n",
      "后续问题：史蒂文·斯皮尔伯格来自哪里？\n",
      "中间答案：美国。\n",
      "后续问题：《皇家赌场》的导演是谁？\n",
      "中间答案：《皇家赌场》的导演是马丁·坎贝尔（Martin Campbell）。\n",
      "后续问题：马丁·坎贝尔来自哪里？\n",
      "中间答案：新西兰。\n",
      "因此最终答案是：不是\n",
      "\n",
      "\n",
      "Question: 爱因斯坦的妻子比爱因斯坦大几岁？\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    suffix=\"Question: {input}\",\n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"爱因斯坦的妻子比爱因斯坦大几岁？\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfb9e0bd-13e2-4caa-9a49-ac5043fd5f61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这里需要后续问题吗：是。\\n后续问题：爱因斯坦的妻子是谁？\\n中间答案：爱因斯坦的妻子是米莉娅·玛里琳娜（Mileva Marić）。\\n后续问题：米莉娅·玛里琳娜比爱因斯坦大几岁？\\n中间答案：米莉娅·玛里琳娜比爱因斯坦大一岁。\\n因此最终答案是：一岁。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(input=\"爱因斯坦的妻子比爱因斯坦大几岁？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5917952-4aad-45e1-ab43-e4a1933b2241",
   "metadata": {},
   "source": [
    "### 3.2 Example selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967ecb6-09a2-44d7-8f4c-fb7bd850e62f",
   "metadata": {},
   "source": [
    "#### 1.use Select by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c26f53d-e5ec-4993-8a68-db96a8e4e51f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "\n",
    "# Examples of a pretend task of creating antonyms.\n",
    "examples = [\n",
    "    {\"input\": \"happy\", \"output\": \"sad\"},\n",
    "    {\"input\": \"tall\", \"output\": \"short\"},\n",
    "    {\"input\": \"energetic\", \"output\": \"lethargic\"},\n",
    "    {\"input\": \"sunny\", \"output\": \"gloomy\"},\n",
    "    {\"input\": \"windy\", \"output\": \"calm\"},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Input: {input}\\nOutput: {output}\",\n",
    ")\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    # The examples it has available to choose from.\n",
    "    examples=examples,\n",
    "    # The PromptTemplate being used to format the examples.\n",
    "    example_prompt=example_prompt,\n",
    "    # The maximum length that the formatted examples should be.\n",
    "    # Length is measured by the get_text_length function below.\n",
    "    max_length=25,\n",
    "    # The function used to get the length of a string, which is used\n",
    "    # to determine which examples to include. It is commented out because\n",
    "    # it is provided as a default value if none is specified.\n",
    "    # get_text_length: Callable[[str], int] = lambda x: len(re.split(\"\\n| \", x))\n",
    ")\n",
    "dynamic_prompt = FewShotPromptTemplate(\n",
    "    # We provide an ExampleSelector instead of examples.\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"Give the antonym of every input\",\n",
    "    suffix=\"Input: {adjective}\\nOutput:\",\n",
    "    input_variables=[\"adjective\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "419f0428-26c3-4d1c-bfd1-b866460d9d94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: tall\n",
      "Output: short\n",
      "\n",
      "Input: energetic\n",
      "Output: lethargic\n",
      "\n",
      "Input: sunny\n",
      "Output: gloomy\n",
      "\n",
      "Input: windy\n",
      "Output: calm\n",
      "\n",
      "Input: big\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "## 输入较短，所以给的示例多\n",
    "print(dynamic_prompt.format(adjective=\"big\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b3e5016-6758-4b2c-b7ea-11079242bb0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the antonym of every input\n",
      "\n",
      "Input: happy\n",
      "Output: sad\n",
      "\n",
      "Input: big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# 输入的内容长，給的示例少\n",
    "long_string = \"big and huge and massive and large and gigantic and tall and much much much much much bigger than everything else\"\n",
    "print(dynamic_prompt.format(adjective=long_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a40a61-0a15-48f5-916f-b6deb414fe04",
   "metadata": {},
   "source": [
    "## 4.Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b244c2-7797-4d88-8981-b7ca2988d51c",
   "metadata": {},
   "source": [
    "语言模型输出文本。但是很多时候，你可能希望获得比纯文本更结构化的信息。这就是输出解析器的用处。\n",
    "\n",
    "输出解析器是帮助结构化语言模型响应的类。一个输出解析器必须实现两个主要方法：\n",
    "\n",
    "\"获取格式指令\"：返回一个包含语言模型输出应如何格式化的字符串的方法。\n",
    "\"解析\"：接受一个字符串（假设是语言模型的响应）并将其解析为某种结构的方法。\n",
    "然后还有一个可选的方法：\n",
    "\n",
    "\"带提示解析\"：接受一个字符串（假设是语言模型的响应）和一个提示（假设是生成此响应的提示），并将其解析为某种结构。提示主要是在OutputParser\n",
    "希望以某种方式重试或修复输出时提供的，它需要来自提示的信息来执行这些操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183d9ac-74e1-485d-89a1-e10f3398c474",
   "metadata": {},
   "source": [
    "### 1.use List parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a7538-c32c-40e1-be17-0236e645877b",
   "metadata": {},
   "source": [
    "当您想返回一个以逗号分隔的项目列表时，可以使用此输出解析器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "88630646-a8d7-4ec1-9867-619dde8fa5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chocolate',\n",
       " 'Vanilla',\n",
       " 'Strawberry',\n",
       " 'Cookies and Cream',\n",
       " 'Mint Chocolate Chip']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "model = OpenAI(model_name=\"gpt-3.5-turbo\",openai_api_base = \"https://newone.nxykj.tech/v1\")\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "\n",
    "## LCEL\n",
    "chain = prompt | model | parser\n",
    "chain.invoke({\"subject\": \"ice cream flavors\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1bdb0-c9be-4db1-b6ac-6e2be131086f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
