{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e948007-1a80-497f-9c88-8ca481c9cb84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForSeq2Seq, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3819623b-2ea2-4ddd-a67a-95d2a28ffe3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'input', 'instruction'],\n",
       "    num_rows: 26858\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.load_from_disk(\"/root/autodl-tmp/weitiao/data/alpaca_data_zh\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b73a625-dcd9-43aa-8d6f-6fb2ac8f23ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/root/autodl-tmp/modelscope/Llama-2-7b-ms', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/root/autodl-tmp/modelscope/Llama-2-7b-ms\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f07f20ea-ac5a-40c7-8ab2-9a32c01eec1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [29871, 233, 181, 136], 'token_type_ids': [0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"æ²…\", add_special_tokens=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b63c5394-53b9-4dc8-b580-185ee4639233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 25638, 2], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"abc \" + tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad2ffa47-bab0-474d-b14c-86b538fa6039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 2], 'token_type_ids': [0, 0], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54ad90a-9d01-4b36-8225-213aad3aca25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [1, 25638, 829, 29879, 29958], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"abc\" + tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad35b3a-6033-43fe-8b4c-45fbf7707bcc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/root/autodl-tmp/modelscope/Llama-2-7b-ms', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3a13f-c156-4115-a7ae-d8d5de642446",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = \"right\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729763e9-7e1d-4731-8608-06fe4a6036de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizerFast(name_or_path='/root/autodl-tmp/modelscope/Llama-2-7b-ms', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ad3d5f3-4c8e-4728-8969-607ee163c9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae85f8ee-a19b-4d65-a8d5-3204fd94bb0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 400\n",
    "    input_ids, attention_mask, labels = [], [], []\n",
    "    instruction = tokenizer(\"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \", add_special_tokens=False)\n",
    "    response = tokenizer(example[\"output\"], add_special_tokens=False)\n",
    "    input_ids = instruction[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.eos_token_id] ## </s>\n",
    "    attention_mask = instruction[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(instruction[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3dc063-4cdb-4f26-bdaf-482ad3f0f9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e9b86ee13d04e5bb237d0f4cb76a879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/26858 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 26858\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds = ds.map(process_func, remove_columns=ds.column_names)\n",
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0b4a35-3250-4524-8722-1a41257d97c2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[12968, 29901, 29871, 30982, 31695, 31863, 31577, 30210, 30457, 30502,\n",
       "         31302, 30858, 30267,    13,    13,  7900, 22137, 29901, 29871, 29871,\n",
       "         30651, 30557, 30392, 30982, 31695, 31863, 31577, 30210, 30457, 30502,\n",
       "         31302, 30858, 30383,    13,    13, 29896, 29889, 29871, 30982, 31695,\n",
       "         31687, 30988, 31704, 30846, 30267, 31951, 30408,   232,   132,   157,\n",
       "           236,   131,   133, 30948, 30210, 31687, 30988, 31894, 30846, 30214,\n",
       "         30847,   233,   152,   166,   233,   176,   168, 30330,   235,   186,\n",
       "           148,   233,   176,   168, 31391,   233,   187,   187,   233,   182,\n",
       "           182, 30214, 30815,   231,   194,   134, 31174, 30869,   235,   164,\n",
       "           131, 31624, 31863, 31577, 30214,   232,   165,   161,   232,   191,\n",
       "           189,   235,   133,   143,   235,   133,   140, 31074, 31180, 30214,\n",
       "         31666, 30417, 31931, 30909,   232,   138,   146, 31022, 30988, 30908,\n",
       "         30267,    13,    13, 29906, 29889, 29871,   232,   160,   138,   235,\n",
       "           164,   164,   236,   168,   177, 31855, 30267, 31951, 30408, 31855,\n",
       "         30406, 30374,   236,   181,   159, 30210,   235,   151,   175, 31854,\n",
       "         30330, 30716, 30801, 30330, 30753, 31112, 30834, 30503,   235,   135,\n",
       "           133,   235,   133,   173,   232,   147,   174, 31180,   231,   192,\n",
       "           145, 30210,   235,   158,   142, 30868,   235,   183,   171, 31855,\n",
       "         30834, 30214,   236,   132,   194,   232,   136,   144, 30528,   234,\n",
       "           182,   153, 30330, 30528,   235,   135,   133,   235,   133,   173,\n",
       "         30503, 30666, 31041, 31855, 31399, 30214, 30651, 30982, 31695, 31863,\n",
       "         31577, 30210,   236,   168,   177, 31855,   231,   188,   163,   233,\n",
       "           134,   178, 30267,    13,    13, 29941, 29889, 29871,   234,   160,\n",
       "           164,   234,   159,   163,   232,   136,   136, 31722, 30267,   234,\n",
       "           160,   164,   234,   159,   163, 30783, 30313, 30988, 31863, 31577,\n",
       "           235,   138,   182, 31057, 30908, 30698, 30214, 30494, 30470, 30313,\n",
       "         31951, 30408, 31370, 30982,   235,   178,   132, 29871, 29955, 29899,\n",
       "         29947, 29871, 30446, 30594, 30210,   234,   160,   164,   234,   159,\n",
       "           163, 30267, 31400, 31076, 30210,   234,   160,   164,   234,   159,\n",
       "           163, 30417, 31931, 30909,   232,   138,   146,   235,   192,   190,\n",
       "           232,   145,   142, 31074, 30214,   231,   194,   134, 31174, 31687,\n",
       "         30988,   233,   132,   165, 31810, 30214, 31666, 31302, 30528, 31368,\n",
       "         31474, 31074, 30503, 31410,   232,   194,   137, 31074, 30267,     2],\n",
       "        [    2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
       "             2,     2,     2,     2, 12968, 29901, 29871, 31201,   236,   138,\n",
       "           141, 30573,   231,   190,   131, 31882, 30651, 30557, 30748, 30354,\n",
       "         31184, 30980, 30909, 29896, 29914, 29946,    13, 31573, 30752, 30383,\n",
       "         29946, 29914, 29896, 29953,    13,    13,  7900, 22137, 29901, 29871,\n",
       "         29871, 29946, 29914, 29896, 29953, 31184, 30909, 29896, 29914, 29946,\n",
       "         30392, 31570, 30573, 30672, 31381, 30682, 30651,   234,   189,   169,\n",
       "         30748, 30748, 30319, 30748, 31763, 30769, 31152, 30651, 31221, 31381,\n",
       "         30210, 30878, 30257, 30539,   234,   189,   169, 30354, 29946, 30214,\n",
       "         31050, 30780, 30419, 29946, 30646, 29946, 30409, 29914,   313, 29896,\n",
       "         29953, 30646, 29946, 30409, 29922, 29896, 29914, 29946, 30267, 30748,\n",
       "         30354, 30210,   234,   189,   169, 30748, 30392, 30406, 30748, 30319,\n",
       "         30503, 30748, 31763, 31152, 30651, 30990, 30980, 30210, 31838,   236,\n",
       "           158,   185,   233,   152,   183, 30354, 30214, 30805, 30746, 30858,\n",
       "         30748, 30354, 30210, 30287, 30502, 30990, 30980, 30210, 30959, 30214,\n",
       "         30810, 31570, 30573, 30748, 30354, 31195,   236,   156,   136, 30429,\n",
       "         30746, 30858, 30743, 30748, 30319, 31152, 30651, 30748, 31763, 30214,\n",
       "         30744, 30651,   232,   144,   182, 30785, 31977, 30502, 30354, 30980,\n",
       "         30594, 31152, 30651, 30980, 30287, 30502, 31838,   236,   158,   185,\n",
       "           233,   152,   183, 30354, 30214, 30748, 30354, 30210, 30959, 30953,\n",
       "         30413, 30437, 31264, 31462, 30267, 30744, 30651, 29946, 29914, 29896,\n",
       "         29953, 29871, 30503, 29896, 29914, 29946, 30392, 31977, 31893, 30413,\n",
       "         30980, 30210, 31900, 31479, 31305, 30607, 30214,   231,   192,   137,\n",
       "           232,   177,   134, 31381, 30210, 30959, 30990, 31184, 30267,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100, 29871,\n",
       "         30651, 30557, 30392, 30982, 31695, 31863, 31577, 30210, 30457, 30502,\n",
       "         31302, 30858, 30383,    13,    13, 29896, 29889, 29871, 30982, 31695,\n",
       "         31687, 30988, 31704, 30846, 30267, 31951, 30408,   232,   132,   157,\n",
       "           236,   131,   133, 30948, 30210, 31687, 30988, 31894, 30846, 30214,\n",
       "         30847,   233,   152,   166,   233,   176,   168, 30330,   235,   186,\n",
       "           148,   233,   176,   168, 31391,   233,   187,   187,   233,   182,\n",
       "           182, 30214, 30815,   231,   194,   134, 31174, 30869,   235,   164,\n",
       "           131, 31624, 31863, 31577, 30214,   232,   165,   161,   232,   191,\n",
       "           189,   235,   133,   143,   235,   133,   140, 31074, 31180, 30214,\n",
       "         31666, 30417, 31931, 30909,   232,   138,   146, 31022, 30988, 30908,\n",
       "         30267,    13,    13, 29906, 29889, 29871,   232,   160,   138,   235,\n",
       "           164,   164,   236,   168,   177, 31855, 30267, 31951, 30408, 31855,\n",
       "         30406, 30374,   236,   181,   159, 30210,   235,   151,   175, 31854,\n",
       "         30330, 30716, 30801, 30330, 30753, 31112, 30834, 30503,   235,   135,\n",
       "           133,   235,   133,   173,   232,   147,   174, 31180,   231,   192,\n",
       "           145, 30210,   235,   158,   142, 30868,   235,   183,   171, 31855,\n",
       "         30834, 30214,   236,   132,   194,   232,   136,   144, 30528,   234,\n",
       "           182,   153, 30330, 30528,   235,   135,   133,   235,   133,   173,\n",
       "         30503, 30666, 31041, 31855, 31399, 30214, 30651, 30982, 31695, 31863,\n",
       "         31577, 30210,   236,   168,   177, 31855,   231,   188,   163,   233,\n",
       "           134,   178, 30267,    13,    13, 29941, 29889, 29871,   234,   160,\n",
       "           164,   234,   159,   163,   232,   136,   136, 31722, 30267,   234,\n",
       "           160,   164,   234,   159,   163, 30783, 30313, 30988, 31863, 31577,\n",
       "           235,   138,   182, 31057, 30908, 30698, 30214, 30494, 30470, 30313,\n",
       "         31951, 30408, 31370, 30982,   235,   178,   132, 29871, 29955, 29899,\n",
       "         29947, 29871, 30446, 30594, 30210,   234,   160,   164,   234,   159,\n",
       "           163, 30267, 31400, 31076, 30210,   234,   160,   164,   234,   159,\n",
       "           163, 30417, 31931, 30909,   232,   138,   146,   235,   192,   190,\n",
       "           232,   145,   142, 31074, 30214,   231,   194,   134, 31174, 31687,\n",
       "         30988,   233,   132,   165, 31810, 30214, 31666, 31302, 30528, 31368,\n",
       "         31474, 31074, 30503, 31410,   232,   194,   137, 31074, 30267,     2],\n",
       "        [ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         29871, 29946, 29914, 29896, 29953, 31184, 30909, 29896, 29914, 29946,\n",
       "         30392, 31570, 30573, 30672, 31381, 30682, 30651,   234,   189,   169,\n",
       "         30748, 30748, 30319, 30748, 31763, 30769, 31152, 30651, 31221, 31381,\n",
       "         30210, 30878, 30257, 30539,   234,   189,   169, 30354, 29946, 30214,\n",
       "         31050, 30780, 30419, 29946, 30646, 29946, 30409, 29914,   313, 29896,\n",
       "         29953, 30646, 29946, 30409, 29922, 29896, 29914, 29946, 30267, 30748,\n",
       "         30354, 30210,   234,   189,   169, 30748, 30392, 30406, 30748, 30319,\n",
       "         30503, 30748, 31763, 31152, 30651, 30990, 30980, 30210, 31838,   236,\n",
       "           158,   185,   233,   152,   183, 30354, 30214, 30805, 30746, 30858,\n",
       "         30748, 30354, 30210, 30287, 30502, 30990, 30980, 30210, 30959, 30214,\n",
       "         30810, 31570, 30573, 30748, 30354, 31195,   236,   156,   136, 30429,\n",
       "         30746, 30858, 30743, 30748, 30319, 31152, 30651, 30748, 31763, 30214,\n",
       "         30744, 30651,   232,   144,   182, 30785, 31977, 30502, 30354, 30980,\n",
       "         30594, 31152, 30651, 30980, 30287, 30502, 31838,   236,   158,   185,\n",
       "           233,   152,   183, 30354, 30214, 30748, 30354, 30210, 30959, 30953,\n",
       "         30413, 30437, 31264, 31462, 30267, 30744, 30651, 29946, 29914, 29896,\n",
       "         29953, 29871, 30503, 29896, 29914, 29946, 30392, 31977, 31893, 30413,\n",
       "         30980, 30210, 31900, 31479, 31305, 30607, 30214,   231,   192,   137,\n",
       "           232,   177,   134, 31381, 30210, 30959, 30990, 31184, 30267,     2]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(tokenized_ds, batch_size=2, collate_fn=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True))\n",
    "ipt = next(enumerate(dl))[1]\n",
    "ipt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a275783-a911-4115-a590-078c69b31313",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-08)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor(1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28b867f2-1a1e-4f16-91c9-8f3f7d5afb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., dtype=torch.float16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.tensor(1e-8).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b3cf9-396a-48cb-a77d-b25e7a36682f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
